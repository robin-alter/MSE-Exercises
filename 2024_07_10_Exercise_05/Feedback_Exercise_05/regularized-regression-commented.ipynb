{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c276540",
   "metadata": {},
   "source": [
    "Exercise 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d432693",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "We used a different approach than the sample solution to get our beta hat but got the same result. </br>\n",
    "Our calculations of the expectation and covariance is identical to the sample solution\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3424fd",
   "metadata": {},
   "source": [
    "Exercise 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe5f1b1",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "Our proof differs in the method from the sample solution, but we arrive at the same result. Both should be correct\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b64cb9",
   "metadata": {},
   "source": [
    "Exercise 03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c22943",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "We largely did the same as the sample solution with the key differences being the data structure for the results. The sample solution is therefore more elegant and robust than our solution. We also forgot to return the active sets and only returned the betas. </br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe57606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix, coo_matrix\n",
    "from scipy.sparse.linalg import lsqr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def omp_regression(X, y , T):\n",
    "    # At the start no columns are active, and all columns count as inactive\n",
    "    active_columns = []\n",
    "    residuals = [y]\n",
    "    betas = []\n",
    "\n",
    "    for t in range(T):\n",
    "        # Calculate all the correlations for each column of X\n",
    "        correlations = [np.abs(np.dot(np.transpose(X)[:, j], residuals[t])) for j in X.shape()[1]]\n",
    "        # Add the highest calculation to the active columns\n",
    "        j = np.argmax(correlations)\n",
    "        active_columns.append(j)\n",
    "        active_X = X[:,active_columns]\n",
    "        # Solution to least squares problem by ridge regression as in the lecture\n",
    "        beta_rr = np.dot(np.linalg.inv(np.dot(np.transpose(active_X),active_X)),np.dot(np.transpose(active_X), y))\n",
    "        betas.append(beta_rr)\n",
    "        # update the residual\n",
    "        residuals.append(y - np.dot(active_X, betas[t]))\n",
    "    return betas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
